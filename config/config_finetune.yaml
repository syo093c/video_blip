training:
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 1
  num_train_epochs: 5
  dataloader_num_workers: 4
  fp16: true
  optim: "adamw_torch"
  learning_rate: 1.0e-4
  logging_steps: 10
  evaluation_strategy: "steps"
  save_strategy: "steps"
  eval_steps: 100000
  save_steps: 1000
  save_total_limit: 30
  report_to: "wandb"
  deepspeed: ds_config/ds_config.json
  output_dir: "/scratch/acf15648au/output_dir/"
